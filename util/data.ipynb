{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d173b2eb032a32",
   "metadata": {},
   "source": [
    "# Dataset Curation for GouGAN using WikiArt and ArtiFact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a4bfe166ca1b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "If you get errors running this cell, ensure the relevant libraries are installed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77018f6a7b0da83d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:04.712941Z",
     "start_time": "2024-12-06T06:17:04.709500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data source\n",
    "import kagglehub\n",
    "\n",
    "# OS\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Data Processing\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "from shutil import copy2\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "\n",
    "# Parallel\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Modelling\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Logging\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set paths to local\n",
    "PATH_WIKIART = \"./datasets/wikiart\"\n",
    "PATH_ARTIFACT = \"./datasets/artifact\"\n",
    "\n",
    "# Dataset split for WikiArt\n",
    "PATH_STYLE = \"./datasets/style\"\n",
    "PATH_STYLE_BALANCED = \"./datasets/style_balanced\"\n",
    "\n",
    "# Dataset split for Artifact\n",
    "PATH_REAL_FAKE_SPLIT = \"./datasets/real-fake-split\"\n",
    "PATH_REAL_FAKE = \"./datasets/real-fake\"\n",
    "PATH_REAL_FAKE_BALANCED = \"./datasets/real-fake_balanced\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681ba2a06c7e71e",
   "metadata": {},
   "source": [
    "# Download Datasets\n",
    "- WARNING: Downloads will take a while & take up a lot of storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87037fce6acd809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:06.068760Z",
     "start_time": "2024-12-06T06:17:05.393175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/peter/.cache/kagglehub/datasets/steubk/wikiart/versions/1\n",
      "Path to dataset files: /home/peter/.cache/kagglehub/datasets/awsaf49/artifact-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download datasets from Kaggle via Kaggle Hub\n",
    "path_wikiart = kagglehub.dataset_download(\"steubk/wikiart\")\n",
    "print(\"Path to dataset files:\", path_wikiart)\n",
    "\n",
    "path_artifact = kagglehub.dataset_download(\"awsaf49/artifact-dataset\")\n",
    "print(\"Path to dataset files:\", path_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59114603385447c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1641125da5d9bd4",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586b6d5f0ed09362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:06.890585Z",
     "start_time": "2024-12-06T06:17:06.880539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Destination folder './datasets/artifact' already exists. Choose a different path or delete it.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy datasets from cache to local workspace\n",
    "def copy_folder(source_folder, destination_folder):\n",
    "    \"\"\"\n",
    "    Copies a folder from the source to the destination.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the source folder.\n",
    "        destination_folder (str): Path to the destination folder.\n",
    "\n",
    "    Returns:\n",
    "        str: Success or error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if source folder exists\n",
    "        if not os.path.exists(source_folder):\n",
    "            return f\"Source folder '{source_folder}' does not exist.\"\n",
    "\n",
    "        # Check if destination folder exists\n",
    "        if os.path.exists(destination_folder):\n",
    "            return f\"Destination folder '{destination_folder}' already exists. Choose a different path or delete it.\"\n",
    "\n",
    "        # Copy the folder\n",
    "        shutil.copytree(source_folder, destination_folder)\n",
    "        return f\"Folder successfully copied to '{destination_folder}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "copy_folder(path_wikiart, \"./datasets/wikiart\")\n",
    "copy_folder(path_artifact, \"./datasets/artifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e3bae461739a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:07.163585Z",
     "start_time": "2024-12-06T06:17:07.153079Z"
    }
   },
   "outputs": [],
   "source": [
    "def balance_datasets(source_folder, target_folder, categories):\n",
    "    \"\"\"\n",
    "    Balances the datasets in train, val, and test splits for all categories.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the folder containing train/val/test splits with categories.\n",
    "        target_folder (str): Path to the folder where the balanced datasets will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        print(f\"Balancing {split} dataset...\")\n",
    "        split_source_folder = os.path.join(source_folder, split)\n",
    "        split_target_folder = os.path.join(target_folder, split)\n",
    "\n",
    "        # Create target split directory\n",
    "        os.makedirs(split_target_folder, exist_ok=True)\n",
    "\n",
    "        # Gather class counts\n",
    "        class_counts = {}\n",
    "        for category in categories:\n",
    "            category_folder = os.path.join(split_source_folder, category)\n",
    "            if os.path.exists(category_folder):\n",
    "                class_counts[category] = len([\n",
    "                    f for f in os.listdir(category_folder) if os.path.isfile(os.path.join(category_folder, f))\n",
    "                ])\n",
    "            else:\n",
    "                class_counts[category] = 0\n",
    "\n",
    "        # Determine the target class size (minimum for undersampling, maximum for oversampling)\n",
    "        target_size = min(class_counts.values())  # Change to `max(class_counts.values())` for oversampling\n",
    "        print(f\"Target size for balancing: {target_size}\")\n",
    "\n",
    "        # Balance each category\n",
    "        for category in categories:\n",
    "            source_category_folder = os.path.join(split_source_folder, category)\n",
    "            target_category_folder = os.path.join(split_target_folder, category)\n",
    "            os.makedirs(target_category_folder, exist_ok=True)\n",
    "\n",
    "            # Get all files in the category\n",
    "            files = [\n",
    "                f for f in os.listdir(source_category_folder)\n",
    "                if os.path.isfile(os.path.join(source_category_folder, f))\n",
    "            ]\n",
    "\n",
    "            # Shuffle for randomness\n",
    "            random.shuffle(files)\n",
    "\n",
    "            # Balance the dataset\n",
    "            if len(files) > target_size:\n",
    "                # Undersample\n",
    "                balanced_files = files[:target_size]\n",
    "            else:\n",
    "                # Oversample\n",
    "                balanced_files = files + random.choices(files, k=target_size - len(files))\n",
    "\n",
    "            # Copy files to the target folder\n",
    "            for file in balanced_files:\n",
    "                copy2(os.path.join(source_category_folder, file), os.path.join(target_category_folder, file))\n",
    "\n",
    "        print(f\"{split} dataset balanced successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7c38130e2a99ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:07.423620Z",
     "start_time": "2024-12-06T06:17:07.419366Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_statistics(dataset_folder, categories):\n",
    "    \"\"\"\n",
    "    Computes the number of images per category (impressionist/non-impressionist)\n",
    "    and per dataset split (train/val/test).\n",
    "\n",
    "    Args:\n",
    "        style_folder (str): Path to the 'style' folder containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary with counts per category and split.\n",
    "    \"\"\"\n",
    "    splits = ['train', 'val', 'test']\n",
    "    stats = {split: {category: 0 for category in categories} for split in splits}\n",
    "\n",
    "    # Traverse the folder structure\n",
    "    for split in splits:\n",
    "        for category in categories:\n",
    "            folder_path = os.path.join(dataset_folder, split, category)\n",
    "            if os.path.exists(folder_path):\n",
    "                num_images = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "                stats[split][category] = num_images\n",
    "            else:\n",
    "                print(f\"Warning: Folder '{folder_path}' does not exist.\")\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c822ed83573a2",
   "metadata": {},
   "source": [
    "### For WikiArt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deba1e83195c94f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:08.480215Z",
     "start_time": "2024-12-06T06:17:08.473868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data to train, val, test sets for torch\n",
    "def prepare_dataloader_folders_wikiart(wikiart_folder, style_folder):\n",
    "    \"\"\"\n",
    "    Prepares a style folder with train/val/test subfolders for impressionist and non-impressionist images.\n",
    "    \n",
    "    Args:\n",
    "        wikiart_folder (str): Path to the 'wikiart' folder containing art categories.\n",
    "        style_folder (str): Path to the 'style' folder to be created.\n",
    "    \"\"\"\n",
    "    random.seed(413)  # Ensure reproducibility\n",
    "\n",
    "    # Define source and target folders\n",
    "    impressionist_folder = os.path.join(wikiart_folder, \"Impressionism\")\n",
    "    post_impressionist_folder = os.path.join(wikiart_folder, \"Post_Impressionism\")\n",
    "\n",
    "    # Ensure source folders exist\n",
    "    if not os.path.exists(impressionist_folder):\n",
    "        raise FileNotFoundError(f\"{impressionist_folder} not found.\")\n",
    "    if not os.path.exists(wikiart_folder):\n",
    "        raise FileNotFoundError(f\"{wikiart_folder} not found.\")\n",
    "\n",
    "    # Create target folders\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for category in ['impressionist', 'non-impressionist']:\n",
    "            target_folder = os.path.join(style_folder, split, category)\n",
    "            os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "    # Helper function to copy a single image\n",
    "    def copy_image(file_path, dst_folder):\n",
    "        shutil.copy(file_path, dst_folder)\n",
    "\n",
    "    # Helper function to copy images with tqdm and parallelism\n",
    "    def copy_images_parallel(src_files, dst_folder, description=\"Copying images\"):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            list(tqdm(executor.map(lambda file: copy_image(file, dst_folder), src_files), total=len(src_files), desc=description, unit=\"file\"))\n",
    "\n",
    "    # Process Impressionist images\n",
    "    impressionist_images = list(Path(impressionist_folder).glob(\"*.jpg\"))\n",
    "    random.shuffle(impressionist_images)\n",
    "    num_total = len(impressionist_images)\n",
    "    train_split, val_split = int(0.8 * num_total), int(0.9 * num_total)\n",
    "\n",
    "    copy_images_parallel(impressionist_images[:train_split], os.path.join(style_folder, 'train', 'impressionist'), \"Copying Impressionist (Train)\")\n",
    "    copy_images_parallel(impressionist_images[train_split:val_split], os.path.join(style_folder, 'val', 'impressionist'), \"Copying Impressionist (Val)\")\n",
    "    copy_images_parallel(impressionist_images[val_split:], os.path.join(style_folder, 'test', 'impressionist'), \"Copying Impressionist (Test)\")\n",
    "\n",
    "    # Process Non-Impressionist images (exclude Post-Impressionism)\n",
    "    for folder in Path(wikiart_folder).iterdir():\n",
    "        if folder.is_dir() and folder.name not in [\"Impressionism\", \"Post_Impressionism\"]:\n",
    "            non_impressionist_images = list(folder.glob(\"*.jpg\"))\n",
    "            random.shuffle(non_impressionist_images)\n",
    "            num_total = len(non_impressionist_images)\n",
    "            train_split, val_split = int(0.8 * num_total), int(0.9 * num_total)\n",
    "\n",
    "            copy_images_parallel(non_impressionist_images[:train_split], os.path.join(style_folder, 'train', 'non-impressionist'), f\"Copying Non-Impressionist (Train) from {folder.name}\")\n",
    "            copy_images_parallel(non_impressionist_images[train_split:val_split], os.path.join(style_folder, 'val', 'non-impressionist'), f\"Copying Non-Impressionist (Val) from {folder.name}\")\n",
    "            copy_images_parallel(non_impressionist_images[val_split:], os.path.join(style_folder, 'test', 'non-impressionist'), f\"Copying Non-Impressionist (Test) from {folder.name}\")\n",
    "\n",
    "    print(f\"Data split and organization complete under {style_folder}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d4651020894d7",
   "metadata": {},
   "source": [
    "### For Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773d9e60b86757b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:09.644692Z",
     "start_time": "2024-12-06T06:17:09.636316Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_real_fake(artifact_folder: str, output_folder: str):\n",
    "    \"\"\"\n",
    "    Splits images from artifact dataset into real and fake categories.\n",
    "    Real images come from imagenet and afhq folders.\n",
    "    Fake images come from all other folders.\n",
    "    \n",
    "    Args:\n",
    "        artifact_folder (str): Path to the artifact dataset root folder\n",
    "        output_folder (str): Path where real/fake folders will be created\n",
    "    \"\"\"\n",
    "    artifact_path = Path(artifact_folder)\n",
    "    output_path = Path(output_folder)\n",
    "    \n",
    "    # Create output directories\n",
    "    real_path = output_path / 'real'\n",
    "    fake_path = output_path / 'fake'\n",
    "    real_path.mkdir(parents=True, exist_ok=True)\n",
    "    fake_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def copy_images_from_dir(src_dir, dst_dir, desc):\n",
    "        \"\"\"Helper function to copy all images from a directory\"\"\"\n",
    "        # Get all image files recursively\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "            image_files.extend(list(src_dir.rglob(ext)))\n",
    "            \n",
    "        # Copy files with progress bar\n",
    "        for img_path in tqdm(image_files, desc=desc):\n",
    "            # Create unique filename to avoid conflicts\n",
    "            unique_name = f\"{src_dir.name}_{img_path.name}\"\n",
    "            shutil.copy2(img_path, dst_dir / unique_name)\n",
    "        \n",
    "        return len(image_files)\n",
    "    \n",
    "    # Process real folders (imagenet and afhq)\n",
    "    real_folders = ['imagenet', 'afhq']\n",
    "    real_count = 0\n",
    "    for folder in real_folders:\n",
    "        folder_path = artifact_path / folder\n",
    "        if folder_path.exists():\n",
    "            count = copy_images_from_dir(folder_path, real_path, f\"Copying {folder} (real)\")\n",
    "            real_count += count\n",
    "            print(f\"Processed {count} images from {folder}\")\n",
    "    \n",
    "    # Process fake folders (everything else except real folders)\n",
    "    fake_count = 0\n",
    "    for folder_path in artifact_path.iterdir():\n",
    "        if folder_path.is_dir() and folder_path.name not in real_folders + ['.git']:\n",
    "            count = copy_images_from_dir(folder_path, fake_path, f\"Copying {folder_path.name} (fake)\")\n",
    "            fake_count += count\n",
    "            print(f\"Processed {count} images from {folder_path.name}\")\n",
    "    \n",
    "    print(f\"\\nComplete!\")\n",
    "    print(f\"Total real images: {real_count}\")\n",
    "    print(f\"Total fake images: {fake_count}\")\n",
    "    print(f\"Output directory: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e368a2853d62ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:10.131591Z",
     "start_time": "2024-12-06T06:17:10.121642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data to train, val, test sets for torch\n",
    "def prepare_dataloader_folders_artifact(artifact_folder, real_fake_folder):\n",
    "    \"\"\"\n",
    "    Prepares a real_fake folder with train/val/test subfolders for real and fake images.\n",
    "    \n",
    "    Args:\n",
    "        artifact_folder (str): Path to the 'artifact' folder containing art categories.\n",
    "        real_fake_folder (str): Path to the 'real_fake' folder to be created.\n",
    "    \"\"\"\n",
    "    random.seed(413)  # Ensure reproducibility\n",
    "\n",
    "    # Define source and target folders\n",
    "    real_folder = os.path.join(artifact_folder, \"real\")\n",
    "    fake_folder = os.path.join(artifact_folder, \"fake\")\n",
    "\n",
    "    # Ensure source folders exist\n",
    "    if not os.path.exists(real_folder):\n",
    "        raise FileNotFoundError(f\"{real_folder} not found.\")\n",
    "    if not os.path.exists(artifact_folder):\n",
    "        raise FileNotFoundError(f\"{artifact_folder} not found.\")\n",
    "\n",
    "    # Create target folders\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for category in ['real', 'fake']:\n",
    "            target_folder = os.path.join(real_fake_folder, split, category)\n",
    "            os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "    # Helper function to copy a single image\n",
    "    def copy_image(file_path, dst_folder):\n",
    "        shutil.copy(file_path, dst_folder)\n",
    "\n",
    "    # Helper function to copy images with tqdm and parallelism\n",
    "    def copy_images_parallel(src_files, dst_folder, description=\"Copying images\"):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            list(tqdm(executor.map(lambda file: copy_image(file, dst_folder), src_files), total=len(src_files), desc=description, unit=\"file\"))\n",
    "\n",
    "    # Process Real images\n",
    "    real_images = list(Path(real_folder).glob(\"*.jpg\"))\n",
    "    random.shuffle(real_images)\n",
    "    num_total = len(real_images)\n",
    "    train_split, val_split = int(0.8 * num_total), int(0.9 * num_total)\n",
    "\n",
    "    copy_images_parallel(real_images[:train_split], os.path.join(real_fake_folder, 'train', 'real'), \"Copying Real (Train)\")\n",
    "    copy_images_parallel(real_images[train_split:val_split], os.path.join(real_fake_folder, 'val', 'real'), \"Copying Real (Val)\")\n",
    "    copy_images_parallel(real_images[val_split:], os.path.join(real_fake_folder, 'test', 'real'), \"Copying Real (Test)\")\n",
    "\n",
    "    # Process Fake images\n",
    "    fake_images = list(Path(fake_folder).glob(\"*.jpg\"))\n",
    "    random.shuffle(fake_images)\n",
    "    num_total = len(fake_images)\n",
    "    train_split, val_split = int(0.8 * num_total), int(0.9 * num_total)\n",
    "\n",
    "    copy_images_parallel(fake_images[:train_split], os.path.join(real_fake_folder, 'train', 'fake'), \"Copying Fake (Train)\")\n",
    "    copy_images_parallel(fake_images[train_split:val_split], os.path.join(real_fake_folder, 'val', 'fake'), \"Copying Fake (Val)\")\n",
    "    copy_images_parallel(fake_images[val_split:], os.path.join(real_fake_folder, 'test', 'fake'), \"Copying Fake (Test)\")\n",
    "\n",
    "    print(f\"Data split and organization complete under {real_fake_folder}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454a8266e93fd4e",
   "metadata": {},
   "source": [
    "## WikiArt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7370acf7fe76b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataloader_folders_wikiart(PATH_WIKIART, PATH_STYLE)\n",
    "balance_datasets(source_folder=PATH_STYLE, target_folder=PATH_STYLE_BALANCED, categories=[\"impressionist\", \"non-impressionist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135df760b6c72d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:14.570892Z",
     "start_time": "2024-12-06T06:17:14.099839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style\n",
      "\n",
      "Train:\n",
      "  Impressionist: 10448 images\n",
      "  Non-impressionist: 48885 images\n",
      "\n",
      "Val:\n",
      "  Impressionist: 1306 images\n",
      "  Non-impressionist: 6186 images\n",
      "\n",
      "Test:\n",
      "  Impressionist: 1306 images\n",
      "  Non-impressionist: 6195 images\n"
     ]
    }
   ],
   "source": [
    "statistics = get_image_statistics(PATH_STYLE, categories=[\"impressionist\", \"non-impressionist\"])\n",
    "print(\"Style\")\n",
    "for split, counts in statistics.items():\n",
    "    print(f\"\\n{split.capitalize()}:\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category.capitalize()}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5eb720651caae27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:15.220889Z",
     "start_time": "2024-12-06T06:17:15.055133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style (Balanced)\n",
      "\n",
      "Train:\n",
      "  Impressionist: 10448 images\n",
      "  Non-impressionist: 10448 images\n",
      "\n",
      "Val:\n",
      "  Impressionist: 1306 images\n",
      "  Non-impressionist: 1306 images\n",
      "\n",
      "Test:\n",
      "  Impressionist: 1306 images\n",
      "  Non-impressionist: 1306 images\n"
     ]
    }
   ],
   "source": [
    "statistics = get_image_statistics(PATH_STYLE_BALANCED, categories=[\"impressionist\", \"non-impressionist\"])\n",
    "print(\"Style (Balanced)\")\n",
    "for split, counts in statistics.items():\n",
    "    print(f\"\\n{split.capitalize()}:\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category.capitalize()}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae401955f6b477f",
   "metadata": {},
   "source": [
    "# Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c2412c7be870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_real_fake(PATH_ARTIFACT, PATH_REAL_FAKE_SPLIT)\n",
    "prepare_dataloader_folders_artifact(PATH_REAL_FAKE_SPLIT, PATH_REAL_FAKE)\n",
    "balance_datasets(source_folder=PATH_REAL_FAKE, target_folder=PATH_REAL_FAKE_BALANCED, categories = [\"real\", \"fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41551a8cb4dd8e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:26.351088Z",
     "start_time": "2024-12-06T06:17:17.979948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-Fake\n",
      "\n",
      "Train:\n",
      "  Real: 102976 images\n",
      "  Fake: 779780 images\n",
      "\n",
      "Val:\n",
      "  Real: 12872 images\n",
      "  Fake: 97472 images\n",
      "\n",
      "Test:\n",
      "  Real: 12873 images\n",
      "  Fake: 97473 images\n"
     ]
    }
   ],
   "source": [
    "statistics = get_image_statistics(PATH_REAL_FAKE, categories=[\"real\", \"fake\"])\n",
    "print(\"Real-Fake\")\n",
    "for split, counts in statistics.items():\n",
    "    print(f\"\\n{split.capitalize()}:\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category.capitalize()}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa855602653a39a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:17:27.886918Z",
     "start_time": "2024-12-06T06:17:26.418408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-Fake (Balanced)\n",
      "\n",
      "Train:\n",
      "  Real: 102976 images\n",
      "  Fake: 102976 images\n",
      "\n",
      "Val:\n",
      "  Real: 12872 images\n",
      "  Fake: 12872 images\n",
      "\n",
      "Test:\n",
      "  Real: 12873 images\n",
      "  Fake: 12873 images\n"
     ]
    }
   ],
   "source": [
    "statistics = get_image_statistics(PATH_REAL_FAKE_BALANCED, categories=[\"real\", \"fake\"])\n",
    "print(\"Real-Fake (Balanced)\")\n",
    "for split, counts in statistics.items():\n",
    "    print(f\"\\n{split.capitalize()}:\")\n",
    "    for category, count in counts.items():\n",
    "        print(f\"  {category.capitalize()}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05a2e41d4506f2",
   "metadata": {},
   "source": [
    "## Tests\n",
    "- Loading each dataset using PyTorch dataloaders\n",
    "- Perform augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882ddd583bad04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Torch Augmentation and Dataloaders\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),           # Resize to 200x200\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # Augment with flipping\n",
    "    transforms.RandomRotation(degrees=10),  # Augment with slight rotation\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                    # Normalize using ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),          # Resize to 200x200\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                    # Normalize using ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Paths to dataset splits\n",
    "train_path = \"./datasets/style_balanced/train\"\n",
    "val_path = \"./datasets/style_balanced/val\"\n",
    "test_path = \"./datasets/style_balanced/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = ImageFolder(root=train_path, transform=train_transforms)\n",
    "val_dataset = ImageFolder(root=val_path, transform=val_test_transforms)\n",
    "test_dataset = ImageFolder(root=test_path, transform=val_test_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define transformations (resize, normalize, etc.)\n",
    "transforms_pipeline = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),          # Resize to 200x200\n",
    "    transforms.ToTensor(),                  # Convert to tensor\n",
    "    transforms.Normalize(                    # Normalize using ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"./datasets/style_balanced/train\"\n",
    "dataset = ImageFolder(root=dataset_path, transform=transforms_pipeline)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Class-to-index mapping\n",
    "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}  # e.g., {0: 'impressionist', 1: 'non-impressionist'}\n",
    "\n",
    "# Helper function to denormalize and convert tensor to image\n",
    "def denormalize_and_convert(image_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    image_tensor = image_tensor * std[:, None, None] + mean[:, None, None]  # Denormalize\n",
    "    image = image_tensor.permute(1, 2, 0).numpy()  # Convert to HWC format for Matplotlib\n",
    "    return image.clip(0, 1)  # Ensure pixel values are in range [0, 1]\n",
    "\n",
    "# Visualize examples\n",
    "def visualize_examples(dataloader, idx_to_class, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualizes a few examples from each category in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): PyTorch DataLoader for the dataset.\n",
    "        idx_to_class (dict): Mapping from class index to class label.\n",
    "        num_samples (int): Number of examples to display per category.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    examples_per_category = {class_name: [] for class_name in idx_to_class.values()}\n",
    "    for images, labels in dataloader:\n",
    "        for image, label in zip(images, labels):\n",
    "            class_name = idx_to_class[label.item()]\n",
    "            if len(examples_per_category[class_name]) < num_samples:\n",
    "                examples_per_category[class_name].append(image)\n",
    "        if all(len(images) >= num_samples for images in examples_per_category.values()):\n",
    "            break\n",
    "\n",
    "    # Plot examples\n",
    "    for category, images in examples_per_category.items():\n",
    "        print(f\"Category: {category}\")\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "        for i, img in enumerate(images):\n",
    "            axes[i].imshow(denormalize_and_convert(img))\n",
    "            axes[i].axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "# Call the function\n",
    "visualize_examples(dataloader, idx_to_class, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a4c9bdc2e9235",
   "metadata": {},
   "source": [
    "## Experimental\n",
    "- **Hybrid Method:** Resize images to $1000 \\times 1000$, then create $200 \\times 200$ patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f902a2fcd9461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patches_for_image(args):\n",
    "    \"\"\"\n",
    "    Resizes an image to 1000x1000 and splits it into 200x200 patches.\n",
    "    We call this the hybrid approach.\n",
    "    \n",
    "    Args:\n",
    "        args (tuple): Contains (image_path, target_folder, patch_size, overlap)\n",
    "    \"\"\"\n",
    "    image_path, target_folder, patch_size, overlap = args\n",
    "    \n",
    "    try:\n",
    "        # Create target directory if it doesn't exist\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        \n",
    "        # Open and resize image to 1000x1000\n",
    "        with Image.open(image_path) as image:\n",
    "            # Convert to RGB if needed\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # Resize to 1000x1000 with antialiasing\n",
    "            image = image.resize((1000, 1000), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Calculate steps for patches\n",
    "            step = patch_size - overlap\n",
    "            num_patches = ((1000 - patch_size) // step + 1) ** 2\n",
    "            \n",
    "            # Create patches\n",
    "            patch_count = 0\n",
    "            for i in range(0, 1000 - patch_size + 1, step):\n",
    "                for j in range(0, 1000 - patch_size + 1, step):\n",
    "                    patch_count += 1\n",
    "                    patch = image.crop((j, i, j + patch_size, i + patch_size))\n",
    "                    \n",
    "                    # Create new filename with patch number\n",
    "                    original_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "                    patch_name = f\"{original_name}_patch_{patch_count:03d}.jpg\"\n",
    "                    \n",
    "                    # Save patch with high quality\n",
    "                    patch.save(\n",
    "                        os.path.join(target_folder, patch_name),\n",
    "                        'JPEG',\n",
    "                        quality=100,\n",
    "                        optimize=True\n",
    "                    )\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "def process_style_folder(root_path, style_folder, patch_size=200, overlap=0, num_workers=4):\n",
    "    \"\"\"\n",
    "    Process all images in a style folder (impressionist or non-impressionist).\n",
    "    \n",
    "    Args:\n",
    "        root_path (str): Base path containing style folders\n",
    "        style_folder (str): Name of the style folder\n",
    "        patch_size (int): Size of patches\n",
    "        overlap (int): Overlap between patches\n",
    "        num_workers (int): Number of parallel workers\n",
    "    \"\"\"\n",
    "    source_folder = os.path.join(root_path, style_folder)\n",
    "    target_folder = source_folder  # Save in the same folder\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [\n",
    "        os.path.join(source_folder, f)\n",
    "        for f in os.listdir(source_folder)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args = [\n",
    "        (image_path, target_folder, patch_size, overlap)\n",
    "        for image_path in image_files\n",
    "    ]\n",
    "    \n",
    "    # Process images in parallel with progress bar\n",
    "    with Pool(num_workers) as pool:\n",
    "        list(tqdm(\n",
    "            pool.imap(create_patches_for_image, args),\n",
    "            total=len(args),\n",
    "            desc=f\"Processing {style_folder}\"\n",
    "        ))\n",
    "\n",
    "# Base path\n",
    "train_path = \"./datasets/style_balanced/train\"\n",
    "\n",
    "# Process both impressionist and non-impressionist folders\n",
    "style_folders = ['impressionist', 'non-impressionist']\n",
    "\n",
    "for style_folder in style_folders:\n",
    "    print(f\"\\nProcessing {style_folder} images...\")\n",
    "    process_style_folder(\n",
    "        root_path=train_path,\n",
    "        style_folder=style_folder,\n",
    "        patch_size=200,\n",
    "        overlap=0,  # 50% would be 100=200*0.5 overlap\n",
    "        num_workers=4\n",
    "    )\n",
    "    print(f\"Completed processing {style_folder} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
